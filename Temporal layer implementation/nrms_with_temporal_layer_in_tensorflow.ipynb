{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfsUu_fjX09s"
   },
   "source": [
    "## NRMS Model with Temporal Layer  \n",
    "### Course: *02456 - Deep Learning*  \n",
    "**Technical University of Denmark (DTU)**  \n",
    "---\n",
    "\n",
    "### 📜 **Context**  \n",
    "- This notebook is created as part of the course *02456 - Deep Learning* at DTU. It demonstrates a news recommender system model using Danish media *Ekstra Bladet*'s dataset to predict user preferences for news articles. The model implementation is inspired by the article [Neural News Recommendation with Multi-Head Self-Attention](https://dl.acm.org/doi/10.1145/3640457.3687164).\n",
    "---\n",
    "\n",
    "### 📝 **Differences from the Original Paper**  \n",
    "- **Adding of Temporal Fetaures**: The published time from the article is taken into account by feeding relative time-deltas into its own layer, which returns discounting factors for the news representation.\n",
    "\n",
    "### 🛠️ **What Does This Script Do?**  \n",
    "1. **Model Creation**:  \n",
    "   - Implements a temporal layer in tensorflow and integrates it to the nrms model.\n",
    "\n",
    "2. **Training**:  \n",
    "   - Trains the model using data from *Ekstra Bladet's \"2024 RecSys Challenge\"*.\n",
    "\n",
    "3. **Evaluation**:  \n",
    "   - Evaluates the model on a dataset from *Ekstra Bladet's \"2024 RecSys Challenge\"*.\n",
    "---\n",
    "\n",
    "### 💻 **Hardware Setup**  \n",
    "- This notebook has been tested on DTU's HPC and Google Colab Pro using a T4 GPU with 50GB of system RAM.\n",
    "---\n",
    "\n",
    "### 🔗 **References**  \n",
    "1. [Neural News Recommendation with Multi-Head Self-Attention](https://dl.acm.org/doi/10.1145/3640457.3687164)  \n",
    "2. [Extra Bladet's \"2024 RecSys Challenge\"](https://recsys.eb.dk/)\n",
    "3. The main script is inspired by the examples from the organisor from the challenge. The Dataloader, Temporal layer and the integration to the original model is completly self created. \n",
    "---\n",
    "\n",
    "### 🖊️ **Authors**  \n",
    "- Simon Stohrer\n",
    "- Jonas Vincent Ralf Dauscher\n",
    "- Jofre Bonillo Mesegué\n",
    "- Jan Christopher Leisbrock\n",
    "- Emil Kragh Toft\n",
    "\n",
    "\n",
    "### **Reproducibility**\n",
    "The path in the following cell needs to be changed to the location, where your src folder is stored. After the load dataset headline, the path for the file location needs to be changed as well. The fraction is set to a very small value to allow a fast execution of the code, but should be set to 1 for score reproduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "w8S18vWvX09w"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Deepl learning/Jan_update/src')  # Add the parent directory to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_7c2L8qX5Y1",
    "outputId": "1eaedad3-4d83-4922-e556-b3af99dad21c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqzjIAPsX09x"
   },
   "source": [
    "## Load functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LBi6wtYX09x"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "import datetime\n",
    "from typing import List, Dict, Any, Tuple, Optional, Union\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "from ebrec.utils._constants import *\n",
    "\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    "    ebnerd_from_path,\n",
    ")\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "from ebrec.models.newsrec.dataloader import NewsrecDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1QL4m1hX09y",
    "outputId": "5e31b4ce-a044-4acb-a7b4-ef098e32d449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"Available devices:\", physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnhmXDhBX09y"
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3jD3aIoX09z"
   },
   "outputs": [],
   "source": [
    "# Make sure that PATH is the Data path for the data provided by ekstra bladet\n",
    "PATH = Path(\"/content/drive/MyDrive/Deepl learning/Jan_update/ebnerd_data\")\n",
    "DATASPLIT = \"ebnerd_small\"\n",
    "DUMP_DIR = Path.joinpath(PATH,\"ebnerd_predictions\")\n",
    "DUMP_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "JcQdi0gKX090"
   },
   "outputs": [],
   "source": [
    "HISTORY_SIZE = 20\n",
    "hparams_nrms.history_size = HISTORY_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w1DNggzX090"
   },
   "outputs": [],
   "source": [
    "# We just want to load the necessary columns\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "# This notebook is just a simple 'get-started'; we down sample the number of samples to just run quickly through it.\n",
    "FRACTION = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNb82KvKX090"
   },
   "source": [
    "In this example we sample the dataset, just to keep it smaller. We'll split the training data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "T000kqB_X090",
    "outputId": "90f25076-f1eb-4727-e010-57c92da391d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 201537\n",
      "Validation samples: 32740\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>impression_id</th><th>impression_time</th><th>article_id_fixed</th><th>article_ids_clicked</th><th>article_ids_inview</th><th>labels</th></tr><tr><td>u32</td><td>u32</td><td>datetime[μs]</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>list[i8]</td></tr></thead><tbody><tr><td>526520</td><td>157014</td><td>2023-05-22 19:50:50</td><td>[9758182, 9761469, … 9770799]</td><td>[9776442]</td><td>[9776394, 9776223, … 9776442]</td><td>[0, 0, … 1]</td></tr><tr><td>526520</td><td>157016</td><td>2023-05-22 19:52:45</td><td>[9758182, 9761469, … 9770799]</td><td>[9776234]</td><td>[9776322, 9776234, … 9220931]</td><td>[0, 1, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ impression_i ┆ impression_t ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ labels      │\n",
       "│ ---     ┆ d            ┆ ime          ┆ ixed         ┆ clicked      ┆ inview       ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ u32          ┆ datetime[μs] ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 526520  ┆ 157014       ┆ 2023-05-22   ┆ [9758182,    ┆ [9776442]    ┆ [9776394,    ┆ [0, 0, … 1] │\n",
       "│         ┆              ┆ 19:50:50     ┆ 9761469, …   ┆              ┆ 9776223, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9770799]     ┆              ┆ 9776442]     ┆             │\n",
       "│ 526520  ┆ 157016       ┆ 2023-05-22   ┆ [9758182,    ┆ [9776234]    ┆ [9776322,    ┆ [0, 1, … 0] │\n",
       "│         ┆              ┆ 19:52:45     ┆ 9761469, …   ┆              ┆ 9776234, …   ┆             │\n",
       "│         ┆              ┆              ┆ 9770799]     ┆              ┆ 9220931]     ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    ebnerd_from_path(\n",
    "        PATH.joinpath(DATASPLIT, \"train\"),\n",
    "        history_size=HISTORY_SIZE,\n",
    "        padding=0,\n",
    "    )\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "dt_split = pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL).max() - timedelta(days=1)\n",
    "df_train = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) < dt_split)\n",
    "df_validation = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) >= dt_split)\n",
    "\n",
    "print(f\"Train samples: {df_train.height}\\nValidation samples: {df_validation.height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvSL7AIXX091"
   },
   "source": [
    "### Test set\n",
    "We'll use the validation set, as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "L9LhpuR2X091"
   },
   "outputs": [],
   "source": [
    "df_test = (\n",
    "    ebnerd_from_path(\n",
    "        PATH.joinpath(DATASPLIT, \"validation\"),\n",
    "        history_size=HISTORY_SIZE,\n",
    "        padding=0,\n",
    "    )\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4MBpceFX091"
   },
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "hsDYYHqYX091",
    "outputId": "6895f40d-8126-4cc6-9442-7a572c8dfc47"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(DATASPLIT+\"/articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPmNH4_SX092"
   },
   "outputs": [],
   "source": [
    "# Prepare temporal features\n",
    "def create_article_time_dict(df_articles: pl.DataFrame) -> Dict[int, datetime]:\n",
    "    \"\"\"Create lookup dictionary for article publishing times\"\"\"\n",
    "    return dict(zip(\n",
    "        df_articles[\"article_id\"].to_list(),\n",
    "        df_articles[\"published_time\"].to_list()\n",
    "    ))\n",
    "article_time_dict = create_article_time_dict(df_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "M2Bi8AQRX092"
   },
   "outputs": [],
   "source": [
    "def prepare_temporal_features(\n",
    "    df: pl.DataFrame,\n",
    "    article_time_dict: Dict[int, datetime],\n",
    "    inview_col: str\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"Add temporal features using vectorized operations.\"\"\"\n",
    "    # Add published times\n",
    "    df = df.with_columns([\n",
    "        pl.col(inview_col).map_elements(\n",
    "            lambda ids: [article_time_dict.get(id) for id in ids],\n",
    "            return_dtype=pl.List(pl.Datetime)\n",
    "        ).alias(f\"published_time_{inview_col}\")\n",
    "    ])\n",
    "    # Add reference date (latest date from inview articles)\n",
    "    df = df.with_columns(\n",
    "        pl.col(f\"published_time_{inview_col}\")\n",
    "        .map_elements(\n",
    "            lambda dates: max((d for d in dates if d), default=None),\n",
    "            return_dtype=pl.Datetime\n",
    "        )\n",
    "        .alias(\"reference_date\")\n",
    "    )\n",
    "    # Calculate time differences in seconds\n",
    "    df = df.with_columns([\n",
    "        pl.struct([f\"published_time_{inview_col}\", \"reference_date\"])\n",
    "        .map_elements(\n",
    "            lambda row: calculate_time_difference_seconds(\n",
    "                row[f\"published_time_{inview_col}\"],\n",
    "                row[\"reference_date\"]\n",
    "            ),\n",
    "            return_dtype=pl.List(pl.Float64)\n",
    "        ).alias(\"time_delta\")\n",
    "    ])\n",
    "    return df\n",
    "def calculate_time_difference_seconds(\n",
    "    timestamps: List[Optional[datetime]],\n",
    "    reference_time: datetime\n",
    ") -> List[Optional[float]]:\n",
    "    \"\"\"Calculate time differences in seconds between timestamps and reference time.\"\"\"\n",
    "    return [\n",
    "        (reference_time - timestamp).total_seconds()\n",
    "        if timestamp else None\n",
    "        for timestamp in timestamps\n",
    "    ]\n",
    "# Create article time dictionary\n",
    "article_time_dict = create_article_time_dict(df_articles)\n",
    "# Add temporal features to your datasets\n",
    "df_train = prepare_temporal_features(\n",
    "    df_train,\n",
    "    article_time_dict,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL\n",
    ")\n",
    "df_validation = prepare_temporal_features(\n",
    "    df_validation,\n",
    "    article_time_dict,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL\n",
    ")\n",
    "df_test = prepare_temporal_features(\n",
    "    df_test,\n",
    "    article_time_dict,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMZ9JnmAX092"
   },
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face.\n",
    "Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "amtdkcXDX092"
   },
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SA3_8dmGX092"
   },
   "source": [
    "# Initiate the customized NRMSTemporal dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Xqg9462KX093"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "from ebrec.utils._articles_behaviors import map_list_article_id_to_value\n",
    "from ebrec.utils._python import (\n",
    "    repeat_by_list_values_from_matrix,\n",
    "    create_lookup_objects,\n",
    ")\n",
    "\n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_USER_COL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ra0052C3X093"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NRMSTemporalDataLoader(NewsrecDataLoader):\n",
    "    \"\"\"DataLoader for NRMS model with temporal features.\n",
    "\n",
    "    This dataloader handles both the article content and temporal features,\n",
    "    ensuring proper shape and normalization of time-based signals.\n",
    "\n",
    "    Attributes:\n",
    "        behaviors (pl.DataFrame): DataFrame containing user behaviors\n",
    "        history_column (str): Name of column containing user history\n",
    "        article_dict (dict): Dictionary mapping article IDs to their embeddings\n",
    "        unknown_representation (str): How to handle unknown articles\n",
    "        eval_mode (bool): Whether in evaluation mode\n",
    "        batch_size (int): Size of batches\n",
    "        inview_col (str): Column name for candidate articles\n",
    "        labels_col (str): Column name for labels\n",
    "        user_col (str): Column name for user IDs\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"Transform article IDs to their corresponding embeddings.\"\"\"\n",
    "        return df.pipe(\n",
    "            map_list_article_id_to_value,\n",
    "            behaviors_column=self.history_column,\n",
    "            mapping=self.lookup_article_index,\n",
    "            fill_nulls=self.unknown_index,\n",
    "            drop_nulls=False,\n",
    "        ).pipe(\n",
    "            map_list_article_id_to_value,\n",
    "            behaviors_column=self.inview_col,\n",
    "            mapping=self.lookup_article_index,\n",
    "            fill_nulls=self.unknown_index,\n",
    "            drop_nulls=False,\n",
    "        )\n",
    "\n",
    "    def normalize_time_deltas(self, time_deltas: np.ndarray, eval_mode: bool = False) -> np.ndarray:\n",
    "        \"\"\"Normalize time deltas and ensure correct shape.\n",
    "\n",
    "        Args:\n",
    "            time_deltas: Array of time differences in seconds\n",
    "            eval_mode: Whether in evaluation mode (affects reshaping)\n",
    "\n",
    "        Returns:\n",
    "            Normalized time deltas with proper shape\n",
    "        \"\"\"\n",
    "        # Add small epsilon to avoid division by zero\n",
    "        epsilon = 1e-10\n",
    "\n",
    "        # Replace None/NaN values with maximum time delta\n",
    "        max_delta = np.nanmax(time_deltas) + epsilon\n",
    "        time_deltas = np.nan_to_num(time_deltas, nan=max_delta)\n",
    "\n",
    "        # Normalize to [0, 1] range using log-scale normalization\n",
    "        # Adding 1 to avoid log(0) and to make very recent items close to 0\n",
    "        normalized = np.log1p(time_deltas) / np.log1p(max_delta)\n",
    "\n",
    "        # Shape handling\n",
    "        if normalized.ndim == 1:\n",
    "            normalized = normalized.reshape(-1, 1)\n",
    "\n",
    "        return normalized\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[tuple[np.ndarray], np.ndarray]:\n",
    "        \"\"\"Get a batch of data.\n",
    "\n",
    "        Args:\n",
    "            idx: Batch index\n",
    "\n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "                - his_input_title: User history article embeddings\n",
    "                - pred_input_title: Candidate article embeddings\n",
    "                - time_deltas: Normalized time differences\n",
    "                - batch_y: Labels\n",
    "        \"\"\"\n",
    "        batch_X = self.X[idx * self.batch_size : (idx + 1) * self.batch_size].pipe(\n",
    "            self.transform\n",
    "        )\n",
    "        batch_y = self.y[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "\n",
    "        if self.eval_mode:\n",
    "            # Evaluation mode - process all candidates\n",
    "            repeats = np.array(batch_X[\"n_samples\"])\n",
    "            batch_y = np.array(batch_y.explode().to_list()).reshape(-1, 1)\n",
    "\n",
    "            # Process history\n",
    "            his_input_title = repeat_by_list_values_from_matrix(\n",
    "                batch_X[self.history_column].to_list(),\n",
    "                matrix=self.lookup_article_matrix,\n",
    "                repeats=repeats,\n",
    "            )\n",
    "\n",
    "            # Process candidates\n",
    "            pred_input_title = self.lookup_article_matrix[\n",
    "                batch_X[self.inview_col].explode().to_list()\n",
    "            ]\n",
    "\n",
    "            # Process time deltas\n",
    "            time_deltas = np.array(batch_X[\"time_delta\"].explode().to_list())\n",
    "            time_deltas = self.normalize_time_deltas(time_deltas, eval_mode=True)\n",
    "\n",
    "        else:\n",
    "            # Training mode - process fixed number of candidates\n",
    "            batch_y = np.array(batch_y.to_list())\n",
    "\n",
    "            # Process history\n",
    "            his_input_title = self.lookup_article_matrix[\n",
    "                batch_X[self.history_column].to_list()\n",
    "            ]\n",
    "\n",
    "            # Process candidates\n",
    "            pred_input_title = self.lookup_article_matrix[\n",
    "                batch_X[self.inview_col].to_list()\n",
    "            ]\n",
    "            pred_input_title = np.squeeze(pred_input_title, axis=2)\n",
    "\n",
    "            # Process time deltas\n",
    "            time_deltas = np.array(batch_X[\"time_delta\"].to_list())\n",
    "            time_deltas = self.normalize_time_deltas(time_deltas)\n",
    "\n",
    "        # Final shape adjustments\n",
    "        his_input_title = np.squeeze(his_input_title, axis=2)\n",
    "\n",
    "        # Ensure time_deltas matches pred_input_title shape for training mode\n",
    "        if not self.eval_mode:\n",
    "            # Reshape time_deltas to match pred_input_title: (batch_size, n_candidates, 1)\n",
    "            time_deltas = time_deltas.reshape(pred_input_title.shape[0], -1, 1)\n",
    "        else:\n",
    "            # For eval mode, maintain the proper shape based on all candidates\n",
    "            time_deltas = time_deltas.reshape(-1, 1, 1)\n",
    "\n",
    "        return (his_input_title, pred_input_title, time_deltas), batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3RlhCgIX093"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataloader = NRMSTemporalDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_dataloader = NRMSTemporalDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the customized Temporal Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "kxbIFIkbX094"
   },
   "outputs": [],
   "source": [
    "class TemporalLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Custom layer to learn temporal relationships in news recommendations.\n",
    "    This layer takes time differences as input and learns a temporal weighting function.\n",
    "    Instead of using a fixed exponential decay, it allows the model to learn the optimal\n",
    "    temporal weighting scheme.\n",
    "    \"\"\"\n",
    "    def __init__(self, units=64, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.dropout_rate = 0.2\n",
    "    def build(self, input_shape):\n",
    "        # Create trainable weights for temporal transformation\n",
    "        self.temporal_transform = tf.keras.layers.Dense(\n",
    "            self.units,\n",
    "            activation=self.activation,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='temporal_transform'\n",
    "        )\n",
    "        # Final projection to scalar weight\n",
    "        self.temporal_intermediate = tf.keras.layers.Dense(\n",
    "            400,\n",
    "            activation=self.activation,  # Ensure output is between 0 and 1\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='temporal_intermediate'\n",
    "        )\n",
    "        # Final projection to scalar weight\n",
    "        self.temporal_intermediate_2 = tf.keras.layers.Dense(\n",
    "            400,\n",
    "            activation=self.activation,  # Ensure output is between 0 and 1\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='temporal_intermediate_2'\n",
    "        )\n",
    "        # Final projection to scalar weight\n",
    "        self.temporal_weight = tf.keras.layers.Dense(\n",
    "            1,\n",
    "            activation='sigmoid',  # Ensure output is between 0 and 1\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='temporal_weight'\n",
    "        )\n",
    "        self.temporal_dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "\n",
    "        super().build(input_shape)\n",
    "    def call(self, inputs, training=None):\n",
    "        # inputs shape: (batch_size, sequence_length, 1)\n",
    "        # Transform temporal features through MLP\n",
    "        x = self.temporal_transform(inputs)  # (batch_size, sequence_length, units)\n",
    "        x = self.temporal_intermediate(x)\n",
    "        x = self.temporal_dropout(x)\n",
    "        x = self.temporal_intermediate_2(x)\n",
    "        x = self.temporal_dropout(x)\n",
    "        # Project to temporal weights\n",
    "        temporal_weights = self.temporal_weight(x)  # (batch_size, sequence_length, 1)\n",
    "\n",
    "        temporal_weights = tf.ensure_shape(temporal_weights, (None, None, 1))\n",
    "        temporal_weights_400 = tf.tile(temporal_weights, [1, 1, 400])  # Shape: (batch_size, 400)\n",
    "        temporal_weights_400 = tf.ensure_shape(temporal_weights_400, (None, None, 400))\n",
    "\n",
    "        return temporal_weights_400  # Will be used for multiplication with news embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVK6FnAVX094"
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License.\n",
    "from ebrec.models.newsrec.layers import AttLayer2, SelfAttention\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Embedding, Input, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.regularizers import l2\n",
    "class NRMSTemporalModel:\n",
    "    \"\"\"NRMS model(Neural News Recommendation with Multi-Head Self-Attention)\n",
    "    Chuhan Wu, Fangzhao Wu, Suyu Ge, Tao Qi, Yongfeng Huang,and Xing Xie, \"Neural News\n",
    "    Recommendation with Multi-Head Self-Attention\" in Proceedings of the 2019 Conference\n",
    "    on Empirical Methods in Natural Language Processing and the 9th International Joint Conference\n",
    "    on Natural Language Processing (EMNLP-IJCNLP)\n",
    "    Attributes:\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        hparams: dict,\n",
    "        word2vec_embedding: np.ndarray = None,\n",
    "        word_emb_dim: int = 300,\n",
    "        vocab_size: int = 32000,\n",
    "        seed: int = None,\n",
    "    ):\n",
    "        \"\"\"Initialization steps for NRMS.\"\"\"\n",
    "        self.hparams = hparams\n",
    "        self.seed = seed\n",
    "        # SET SEED:\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        # INIT THE WORD-EMBEDDINGS:\n",
    "        if word2vec_embedding is None:\n",
    "            # Xavier Initialization\n",
    "            initializer = GlorotUniform(seed=self.seed)\n",
    "            self.word2vec_embedding = initializer(shape=(vocab_size, word_emb_dim))\n",
    "            # self.word2vec_embedding = np.random.rand(vocab_size, word_emb_dim)\n",
    "        else:\n",
    "            self.word2vec_embedding = word2vec_embedding\n",
    "        # BUILD AND COMPILE MODEL:\n",
    "        self.model, self.scorer = self._build_graph()\n",
    "        data_loss = self._get_loss(self.hparams.loss)\n",
    "        train_optimizer = self._get_opt(\n",
    "            optimizer=self.hparams.optimizer, lr=self.hparams.learning_rate\n",
    "        )\n",
    "        self.model.compile(loss=data_loss, optimizer=train_optimizer)\n",
    "    def _get_loss(self, loss: str):\n",
    "        \"\"\"Make loss function, consists of data loss and regularization loss\n",
    "        Returns:\n",
    "            object: Loss function or loss function name\n",
    "        \"\"\"\n",
    "        if loss == \"cross_entropy_loss\":\n",
    "            data_loss = \"categorical_crossentropy\"\n",
    "        elif loss == \"log_loss\":\n",
    "            data_loss = \"binary_crossentropy\"\n",
    "        else:\n",
    "            raise ValueError(f\"this loss not defined {loss}\")\n",
    "        return data_loss\n",
    "    def _get_opt(self, optimizer: str, lr: float):\n",
    "        \"\"\"Get the optimizer according to configuration. Usually we will use Adam.\n",
    "        Returns:\n",
    "            object: An optimizer.\n",
    "        \"\"\"\n",
    "        # TODO: shouldn't be a string input you should just set the optimizer, to avoid stuff like this:\n",
    "        # => 'WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.'\n",
    "        if optimizer == \"adam\":\n",
    "            train_opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        else:\n",
    "            raise ValueError(f\"this optimizer not defined {optimizer}\")\n",
    "        return train_opt\n",
    "    def _build_graph(self):\n",
    "        \"\"\"Build NRMS model and scorer.\n",
    "        Returns:\n",
    "            object: a model used to train.\n",
    "            object: a model used to evaluate and inference.\n",
    "        \"\"\"\n",
    "        model, scorer = self._build_nrms()\n",
    "        return model, scorer\n",
    "    def _build_userencoder(self, titleencoder):\n",
    "        \"\"\"The main function to create user encoder of NRMS.\n",
    "        Args:\n",
    "            titleencoder (object): the news encoder of NRMS.\n",
    "        Return:\n",
    "            object: the user encoder of NRMS.\n",
    "        \"\"\"\n",
    "        his_input_title = tf.keras.Input(\n",
    "            shape=(self.hparams.history_size, self.hparams.title_size), dtype=\"int32\"\n",
    "        )\n",
    "        click_title_presents = tf.keras.layers.TimeDistributed(titleencoder)(\n",
    "            his_input_title\n",
    "        )\n",
    "        y = SelfAttention(self.hparams.head_num, self.hparams.head_dim, seed=self.seed)(\n",
    "            [click_title_presents] * 3\n",
    "        )\n",
    "        user_present = AttLayer2(self.hparams.attention_hidden_dim, seed=self.seed)(y)\n",
    "        model = tf.keras.Model(his_input_title, user_present, name=\"user_encoder\")\n",
    "        return model\n",
    "    def _build_newsencoder(self):\n",
    "        \"\"\"The main function to create news encoder of NRMS.\n",
    "        Args:\n",
    "            embedding_layer (object): a word embedding layer.\n",
    "        Return:\n",
    "            object: the news encoder of NRMS.\n",
    "        \"\"\"\n",
    "        embedding_layer = tf.keras.layers.Embedding(\n",
    "            self.word2vec_embedding.shape[0],\n",
    "            self.word2vec_embedding.shape[1],\n",
    "            weights=[self.word2vec_embedding],\n",
    "            trainable=True,\n",
    "        )\n",
    "        sequences_input_title = tf.keras.Input(\n",
    "            shape=(self.hparams.title_size,), dtype=\"int32\"\n",
    "        )\n",
    "        embedded_sequences_title = embedding_layer(sequences_input_title)\n",
    "        y = tf.keras.layers.Dropout(self.hparams.dropout)(embedded_sequences_title)\n",
    "        y = SelfAttention(self.hparams.head_num, self.hparams.head_dim, seed=self.seed)(\n",
    "            [y, y, y]\n",
    "        )\n",
    "        # Create configurable Dense layers:\n",
    "        for layer in [400, 400, 400]:\n",
    "            y = tf.keras.layers.Dense(units=layer, activation=\"relu\")(y)\n",
    "            y = tf.keras.layers.BatchNormalization()(y)\n",
    "            y = tf.keras.layers.Dropout(self.hparams.dropout)(y)\n",
    "        y = tf.keras.layers.Dropout(self.hparams.dropout)(y)\n",
    "        pred_title = AttLayer2(self.hparams.attention_hidden_dim, seed=self.seed)(y)\n",
    "        model = tf.keras.Model(sequences_input_title, pred_title, name=\"news_encoder\")\n",
    "        return model\n",
    "    def _build_nrms(self):\n",
    "\n",
    "        \"\"\"Build NRMS model with learned temporal features.\n",
    "\n",
    "        Instead of using pre-computed temporal discounts, this version learns\n",
    "\n",
    "        temporal relationships from raw time differences.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Input layers\n",
    "\n",
    "        his_input_title = tf.keras.Input(\n",
    "\n",
    "            shape=(self.hparams.history_size, self.hparams.title_size),\n",
    "\n",
    "            dtype=\"int32\",\n",
    "\n",
    "        )\n",
    "\n",
    "        pred_input_title = tf.keras.Input(\n",
    "\n",
    "            shape=(None, self.hparams.title_size),\n",
    "\n",
    "            dtype=\"int32\",\n",
    "\n",
    "        )\n",
    "\n",
    "        pred_input_title_one = tf.keras.Input(\n",
    "\n",
    "            shape=(1, self.hparams.title_size),\n",
    "\n",
    "            dtype=\"int32\",\n",
    "\n",
    "        )\n",
    "\n",
    "        # Time delta inputs (now just raw time differences)\n",
    "\n",
    "        time_delta = tf.keras.Input(\n",
    "\n",
    "            shape=(None, 1), dtype=\"float32\"\n",
    "\n",
    "        )\n",
    "\n",
    "        time_delta_one = tf.keras.Input(\n",
    "\n",
    "            shape=(1, 1), dtype=\"float32\"\n",
    "\n",
    "        )\n",
    "\n",
    "        # Reshape single prediction input\n",
    "\n",
    "        pred_title_one_reshape = tf.keras.layers.Reshape(\n",
    "\n",
    "            (self.hparams.title_size,)\n",
    "\n",
    "        )(pred_input_title_one)\n",
    "\n",
    "        # Build encoders\n",
    "\n",
    "        titleencoder = self._build_newsencoder()\n",
    "\n",
    "        self.userencoder = self._build_userencoder(titleencoder)\n",
    "\n",
    "        self.newsencoder = titleencoder\n",
    "\n",
    "        # Get user representation\n",
    "\n",
    "        user_present = self.userencoder(his_input_title)\n",
    "\n",
    "        # Get news representations\n",
    "\n",
    "        news_present = tf.keras.layers.TimeDistributed(self.newsencoder)(\n",
    "\n",
    "            pred_input_title\n",
    "\n",
    "        )\n",
    "\n",
    "        news_present_one = self.newsencoder(pred_title_one_reshape)\n",
    "\n",
    "        # Create temporal layer\n",
    "        temporal_layer = TemporalLayer(units=64, name='temporal_layer')\n",
    "\n",
    "        # Learn temporal weights and apply them\n",
    "        temporal_weights = temporal_layer(time_delta)\n",
    "        print(temporal_weights)\n",
    "\n",
    "        temporal_weights_one = temporal_layer(time_delta_one)\n",
    "   \n",
    "        # Apply temporal weights to news representations\n",
    "        news_present = tf.keras.layers.Multiply()([news_present, temporal_weights])\n",
    "        news_present_one = tf.keras.layers.Multiply()([news_present_one, temporal_weights_one])\n",
    "\n",
    "        # Compute final predictions\n",
    "        preds = tf.keras.layers.Dot(axes=-1)([news_present, user_present])\n",
    "        preds = tf.keras.layers.Activation(activation=\"softmax\")(preds)\n",
    "        pred_one = tf.keras.layers.Dot(axes=-1)([news_present_one, user_present])\n",
    "        pred_one = tf.keras.layers.Activation(activation=\"sigmoid\")(pred_one)\n",
    "\n",
    "        # Create models\n",
    "\n",
    "        model = tf.keras.Model(\n",
    "\n",
    "            [his_input_title, pred_input_title, time_delta],\n",
    "\n",
    "            preds\n",
    "\n",
    "        )\n",
    "\n",
    "        scorer = tf.keras.Model(\n",
    "\n",
    "            [his_input_title, pred_input_title_one, time_delta_one],\n",
    "\n",
    "            pred_one\n",
    "\n",
    "        )\n",
    "\n",
    "        return model, scorer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWhcyVhVX095",
    "outputId": "6677c02d-fcee-40d9-dd74-8fec7431380c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, None, 400), dtype=float32, sparse=False, name=keras_tensor_73>\n"
     ]
    }
   ],
   "source": [
    "model = NRMSTemporalModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "model.model.compile(\n",
    "    optimizer=model.model.optimizer,\n",
    "    loss=model.model.loss,\n",
    "    metrics=[\"AUC\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_KguhlvoX095",
    "outputId": "149254d3-6087-4ed7-ade0-1b108affdb28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_10            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ time_distributed_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">193,489,536</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ temporal_layer            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">186,929</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TemporalLayer</span>)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ multiply_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                           │                        │                │ temporal_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ user_encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">194,049,936</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dot_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                           │                        │                │ user_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_10            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ time_distributed_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)      │    \u001b[38;5;34m193,489,536\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ temporal_layer            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m400\u001b[0m)         │        \u001b[38;5;34m186,929\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mTemporalLayer\u001b[0m)           │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m30\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ multiply_2 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ time_distributed_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                           │                        │                │ temporal_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ user_encoder (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │    \u001b[38;5;34m194,049,936\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dot_2 (\u001b[38;5;33mDot\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                           │                        │                │ user_encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ dot_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">194,236,865</span> (740.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m194,236,865\u001b[0m (740.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">194,234,465</span> (740.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m194,234,465\u001b[0m (740.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,400</span> (9.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,400\u001b[0m (9.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "News Encoder Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"news_encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"news_encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">192,001,536</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ self_attention_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">921,600</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)           │                        │                │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                           │                        │                │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160,400</span> │ self_attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160,400</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160,400</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ att_layer2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttLayer2</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m768\u001b[0m)        │    \u001b[38;5;34m192,001,536\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m768\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ self_attention_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │        \u001b[38;5;34m921,600\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)           │                        │                │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                           │                        │                │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │        \u001b[38;5;34m160,400\u001b[0m │ self_attention_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │          \u001b[38;5;34m1,600\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │        \u001b[38;5;34m160,400\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │          \u001b[38;5;34m1,600\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │        \u001b[38;5;34m160,400\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │          \u001b[38;5;34m1,600\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ att_layer2_2 (\u001b[38;5;33mAttLayer2\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │         \u001b[38;5;34m80,400\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193,489,536</span> (738.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m193,489,536\u001b[0m (738.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193,487,136</span> (738.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193,487,136\u001b[0m (738.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,400</span> (9.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,400\u001b[0m (9.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Encoder Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"user_encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"user_encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ time_distributed_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">193,489,536</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ self_attention_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">480,000</span> │ time_distributed_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)           │                        │                │ time_distributed_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                           │                        │                │ time_distributed_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ att_layer2_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttLayer2</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ self_attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m30\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ time_distributed_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │    \u001b[38;5;34m193,489,536\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ self_attention_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m400\u001b[0m)        │        \u001b[38;5;34m480,000\u001b[0m │ time_distributed_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)           │                        │                │ time_distributed_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                           │                        │                │ time_distributed_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ att_layer2_3 (\u001b[38;5;33mAttLayer2\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │         \u001b[38;5;34m80,400\u001b[0m │ self_attention_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">194,049,936</span> (740.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m194,049,936\u001b[0m (740.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">194,047,536</span> (740.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m194,047,536\u001b[0m (740.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,400</span> (9.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,400\u001b[0m (9.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model summary\n",
    "def print_model_summary(model):\n",
    "    \"\"\"Print detailed summary of model architecture\"\"\"\n",
    "    # Print overall model summary\n",
    "    print(\"Overall Model Summary:\")\n",
    "    model.model.summary()\n",
    "    # Print individual component summaries\n",
    "    print(\"\\nNews Encoder Summary:\")\n",
    "    model.newsencoder.summary()\n",
    "    print(\"\\nUser Encoder Summary:\")\n",
    "    model.userencoder.summary()\n",
    "\n",
    "# Plot model architecture\n",
    "def plot_model_architecture(model, filename=\"nrms_model.png\"):\n",
    "    \"\"\"Save visualization of model architecture\"\"\"\n",
    "    tf.keras.utils.plot_model(\n",
    "        model.model,\n",
    "        to_file=filename,\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        rankdir=\"TB\",\n",
    "        expand_nested=True,\n",
    "        dpi=96,\n",
    "    )\n",
    "\n",
    "# Usage:\n",
    "print_model_summary(model)\n",
    "plot_model_architecture(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jf79l09JX093"
   },
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDPi_b1oX094",
    "outputId": "75f6d537-d4ec-43d7-e927-4af1103ad00d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"Available devices:\", physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dN9d5xx9X096",
    "outputId": "89993d0d-59ab-4337-a7f2-56da0d3b4869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Deepl learning/Jan_update/ebnerd_data/ebnerd_predictions/state_dict/NRMSTemporalModel/mini_0_1_fraction_small_dataset_with_normalization.weights.h5\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 192001536 elements. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - AUC: 0.5505 - loss: 1.7850\n",
      "Epoch 1: saving model to /content/drive/MyDrive/Deepl learning/Jan_update/ebnerd_data/ebnerd_predictions/state_dict/NRMSTemporalModel/mini_0_1_fraction_small_dataset_with_normalization.weights.h5\n",
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 493ms/step - AUC: 0.5506 - loss: 1.7846 - val_AUC: 0.6002 - val_loss: 1.7131 - learning_rate: 1.0000e-04\n",
      "Epoch 2/4\n",
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - AUC: 0.7077 - loss: 1.4276\n",
      "Epoch 2: saving model to /content/drive/MyDrive/Deepl learning/Jan_update/ebnerd_data/ebnerd_predictions/state_dict/NRMSTemporalModel/mini_0_1_fraction_small_dataset_with_normalization.weights.h5\n",
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 197ms/step - AUC: 0.7077 - loss: 1.4276 - val_AUC: 0.6485 - val_loss: 1.5866 - learning_rate: 1.0000e-04\n",
      "Epoch 3/4\n",
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - AUC: 0.7482 - loss: 1.3524\n",
      "Epoch 3: saving model to /content/drive/MyDrive/Deepl learning/Jan_update/ebnerd_data/ebnerd_predictions/state_dict/NRMSTemporalModel/mini_0_1_fraction_small_dataset_with_normalization.weights.h5\n",
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 208ms/step - AUC: 0.7482 - loss: 1.3524 - val_AUC: 0.6733 - val_loss: 1.5873 - learning_rate: 1.0000e-04\n",
      "Epoch 4/4\n",
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - AUC: 0.7681 - loss: 1.3084\n",
      "Epoch 4: saving model to /content/drive/MyDrive/Deepl learning/Jan_update/ebnerd_data/ebnerd_predictions/state_dict/NRMSTemporalModel/mini_0_1_fraction_small_dataset_with_normalization.weights.h5\n",
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 195ms/step - AUC: 0.7681 - loss: 1.3083 - val_AUC: 0.7061 - val_loss: 1.5244 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = model.__class__.__name__\n",
    "MODEL_WEIGHTS = DUMP_DIR.joinpath(f\"state_dict/{MODEL_NAME}/mini_0_1_fraction_small_dataset_with_normalization.weights.h5\")\n",
    "LOG_DIR = DUMP_DIR.joinpath(f\"runs/{MODEL_NAME}\")\n",
    "\n",
    "\n",
    "# Earlystopping:\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_AUC\",\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# ModelCheckpoint:\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=MODEL_WEIGHTS,\n",
    "    monitor=\"val_AUC\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Learning rate scheduler:\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_AUC\",\n",
    "    mode=\"max\",\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, modelcheckpoint, lr_scheduler]#tensorboard_callback\n",
    "USE_CALLBACKS = True\n",
    "EPOCHS = 4\n",
    "\n",
    "hist = model.model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks if USE_CALLBACKS else [],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Esqs6zLeX097"
   },
   "outputs": [],
   "source": [
    "if USE_CALLBACKS:\n",
    "    _ = model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ukagu9LgX097"
   },
   "source": [
    "# Compute some metrics on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "PZsp9uG2X098"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE_TEST = 512\n",
    "\n",
    "test_dataloader = NRMSTemporalDataLoader(\n",
    "    behaviors=df_test,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0qijrcwX099",
    "outputId": "6d9266f5-1e5d-4b83-a54d-08d430d44f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m420/478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m10:11\u001b[0m 11s/step"
     ]
    }
   ],
   "source": [
    "pred_test = model.scorer.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qo8ecFseX099"
   },
   "source": [
    "## Add the predictions to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXy6nfxAQZNF"
   },
   "outputs": [],
   "source": [
    "from typing import Any, Iterable\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import datetime\n",
    "import inspect\n",
    "\n",
    "\n",
    "from ebrec.utils._polars import (\n",
    "    slice_join_dataframes,\n",
    "    _check_columns_in_df,\n",
    "    drop_nulls_from_list,\n",
    "    generate_unique_name,\n",
    "    shuffle_list_column,\n",
    ")\n",
    "import polars as pl\n",
    "\n",
    "from ebrec.utils._constants import *\n",
    "from ebrec.utils._python import create_lookup_dict\n",
    "def add_prediction_scores(\n",
    "    df: pl.DataFrame,\n",
    "    scores: Iterable[float],\n",
    "    prediction_scores_col: str = \"scores\",\n",
    "    inview_col: str = DEFAULT_INVIEW_ARTICLES_COL,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds prediction scores to a DataFrame for the corresponding test predictions.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): The DataFrame to which the prediction scores will be added.\n",
    "        test_prediction (Iterable[float]): A list, array or simialr of prediction scores for the test data.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The DataFrame with the prediction scores added.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If there is a mismatch in the lengths of the list columns.\n",
    "\n",
    "    >>> from ebrec.utils._constants import DEFAULT_INVIEW_ARTICLES_COL\n",
    "    >>> df = pl.DataFrame(\n",
    "            {\n",
    "                \"id\": [1,2],\n",
    "                DEFAULT_INVIEW_ARTICLES_COL: [\n",
    "                    [1, 2, 3],\n",
    "                    [4, 5],\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "    >>> test_prediction = [[0.3], [0.4], [0.5], [0.6], [0.7]]\n",
    "    >>> add_prediction_scores(df.lazy(), test_prediction).collect()\n",
    "        shape: (2, 3)\n",
    "        ┌─────┬─────────────┬────────────────────────┐\n",
    "        │ id  ┆ article_ids ┆ prediction_scores_test │\n",
    "        │ --- ┆ ---         ┆ ---                    │\n",
    "        │ i64 ┆ list[i64]   ┆ list[f32]              │\n",
    "        ╞═════╪═════════════╪════════════════════════╡\n",
    "        │ 1   ┆ [1, 2, 3]   ┆ [0.3, 0.4, 0.5]        │\n",
    "        │ 2   ┆ [4, 5]      ┆ [0.6, 0.7]             │\n",
    "        └─────┴─────────────┴────────────────────────┘\n",
    "    ## The input can can also be an np.array\n",
    "    >>> add_prediction_scores(df.lazy(), np.array(test_prediction)).collect()\n",
    "        shape: (2, 3)\n",
    "        ┌─────┬─────────────┬────────────────────────┐\n",
    "        │ id  ┆ article_ids ┆ prediction_scores_test │\n",
    "        │ --- ┆ ---         ┆ ---                    │\n",
    "        │ i64 ┆ list[i64]   ┆ list[f32]              │\n",
    "        ╞═════╪═════════════╪════════════════════════╡\n",
    "        │ 1   ┆ [1, 2, 3]   ┆ [0.3, 0.4, 0.5]        │\n",
    "        │ 2   ┆ [4, 5]      ┆ [0.6, 0.7]             │\n",
    "        └─────┴─────────────┴────────────────────────┘\n",
    "    \"\"\"\n",
    "    GROUPBY_ID = generate_unique_name(df.columns, \"_groupby_id\")\n",
    "    #print(GROUPBY_ID)\n",
    "    # df_preds = pl.DataFrame()\n",
    "    scores = (\n",
    "        df.lazy()\n",
    "        .select(pl.col(inview_col))\n",
    "        .with_row_index(GROUPBY_ID)\n",
    "        .explode(inview_col)\n",
    "        .with_columns(pl.Series(prediction_scores_col, scores).explode())\n",
    "        .group_by(GROUPBY_ID)\n",
    "        .agg(inview_col, prediction_scores_col)\n",
    "        .sort(GROUPBY_ID)\n",
    "        .collect()\n",
    "    )\n",
    "    return df.with_columns(scores.select(prediction_scores_col))#.drop(GROUPBY_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZ6qwrB6X099"
   },
   "outputs": [],
   "source": [
    "df_test = add_prediction_scores(df_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOdYQEKkX09-"
   },
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oW94AjdqX09-",
    "outputId": "fc446c3b-2a69-4e01-c9a2-642665887d7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUC: 100%|█████████████████████████████| 244647/244647 [05:49<00:00, 699.64it/s]\n",
      "AUC: 100%|███████████████████████████| 244647/244647 [00:06<00:00, 40561.90it/s]\n",
      "AUC: 100%|███████████████████████████| 244647/244647 [00:13<00:00, 17681.06it/s]\n",
      "AUC: 100%|███████████████████████████| 244647/244647 [00:14<00:00, 17434.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 0.639020025664197,\n",
       "    \"mrr\": 0.413061618053277,\n",
       "    \"ndcg@5\": 0.46424257054059764,\n",
       "    \"ndcg@10\": 0.5231771458662604\n",
       "}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = MetricEvaluator(\n",
    "    labels=df_test[\"labels\"].to_list(),\n",
    "    predictions=df_test[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the resulting Temporal Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-PjWBLrJHgaz",
    "outputId": "27913bc4-a455-4443-addc-c3392495a3fc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def analyze_temporal_weights(nrms_model, hours_range=(0, 1), num_points=100):\n",
    "    \"\"\"Analyze and visualize the temporal weights learned by the model.\n",
    "\n",
    "    Args:\n",
    "        nrms_model: Instance of NRMSTemporalModel\n",
    "        hours_range: Tuple of (min_hours, max_hours) to analyze\n",
    "        num_points: Number of points to sample within the hours range\n",
    "\n",
    "    Returns:\n",
    "        tuple: (time_points, weights) - Arrays containing the analyzed data\n",
    "    \"\"\"\n",
    "    # Generate time differences (convert hours to your model's time unit)\n",
    "    hours = np.linspace(hours_range[0], hours_range[1], num_points)\n",
    "\n",
    "    # Get the temporal layer from the model\n",
    "    # First, get the base Keras model\n",
    "    model = nrms_model.model\n",
    "\n",
    "    # Find the temporal layer\n",
    "    temporal_layer = None\n",
    "    for layer in model.layers:\n",
    "        if layer.name == 'temporal_layer':\n",
    "            temporal_layer = layer\n",
    "            break\n",
    "\n",
    "    if temporal_layer is None:\n",
    "        raise ValueError(\"Could not find TemporalLayer in the model\")\n",
    "\n",
    "    # Prepare batch of time differences\n",
    "    time_diffs = hours.reshape(-1, 1, 1)  # Shape: (num_points, 1, 1)\n",
    "\n",
    "    # Get temporal weights\n",
    "    temporal_weights = temporal_layer(time_diffs)  # Shape: (num_points, 1, 400)\n",
    "\n",
    "    # Average weights across the embedding dimension\n",
    "    mean_weights = tf.reduce_mean(temporal_weights, axis=-1).numpy().flatten()\n",
    "\n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(hours, mean_weights, 'b-', linewidth=2)\n",
    "    plt.fill_between(hours, mean_weights, alpha=0.2)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.title('Learned Temporal Importance Weights', fontsize=14, pad=20)\n",
    "    plt.xlabel('Normalized Time Since Publication', fontsize=12)\n",
    "    plt.ylabel('Temporal Weight', fontsize=12)\n",
    "\n",
    "    # Add explanatory text\n",
    "    plt.figtext(0.02, -0.1,\n",
    "                'Higher weights indicate greater importance in the recommendation system.\\n' +\n",
    "                'Shows how the model weights news articles based on their age.',\n",
    "                fontsize=10, ha='left')\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Return the raw data for further analysis if needed\n",
    "    return hours, mean_weights\n",
    "\n",
    "\n",
    "hours, weights = analyze_temporal_weights(model, hours_range=(0, 1), num_points=1000)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
